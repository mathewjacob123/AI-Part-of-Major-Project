{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class LLaMA2HomeAutomation:\n",
    "    def __init__(self, model_size: str = \"7B\"):\n",
    "        \"\"\"Initialize LLaMA 2 for home automation\"\"\"\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_use_double_quant=True\n",
    "        )\n",
    "\n",
    "        model_name = f\"meta-llama/Llama-2-{model_size}-chat-hf\"\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_name,\n",
    "            token = \"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\"\n",
    "        )\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token  #to fix the attention mask warning (ples google)\n",
    "\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map = \"auto\",\n",
    "            token = \"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\"\n",
    "        )\n",
    "\n",
    "    def _create_system_prompt(self) -> str:\n",
    "        \"\"\"Create system prompt for LLaMA 2.\"\"\"\n",
    "        return   \"\"\"You are a home automation AI assistant. Analyze the device usage patterns and create a schedule that follows these exact rules:\n",
    "1. Focus on finding patterns for when devices are turned off or have fan speed changed\n",
    "2. The schedule ID must be in format: ID<YYYYMMDD><HHMMSS><XX> where:\n",
    "   - YYYYMMDD is current date\n",
    "   - HHMMSS is the scheduled time\n",
    "   - XX is a sequence number (01)\n",
    "3. The time must be in HHMMSS format matching when the pattern occurs\n",
    "4. Respond ONLY with a JSON object in this exact format, no other text:\n",
    "{\n",
    "  \"list\": [\n",
    "    [\"ONF\", \"device_id\", \"state\", \"schedule_id\"],\n",
    "    [\"ONF\", \"device_id\", \"state\", \"schedule_id\"]\n",
    "  ],\n",
    "  \"id\": \"schedule_id\",\n",
    "  \"time\": \"HHMMSS\"\n",
    "}\n",
    "Important: Always use the actual device ID from the input data, not the placeholder 'device_id'.\"\"\"\n",
    "\n",
    "    def _create_user_prompt(self, history_data: List[Dict]) -> str:\n",
    "        \"\"\"Create detailed prompt from history data.\"\"\"\n",
    "        # Extract unique devices for reference\n",
    "        unique_devices = set(event['switchbox_id'] for event in history_data)\n",
    "        device_patterns = {}\n",
    "        \n",
    "        # Analyze patterns for each device\n",
    "        for device in unique_devices:\n",
    "            device_events = [event for event in history_data if event['switchbox_id'] == device]\n",
    "            if device_events:\n",
    "                device_patterns[device] = {\n",
    "                    'room': device_events[0]['room_id'],\n",
    "                    'states': [event['state'] for event in device_events]\n",
    "                }\n",
    "\n",
    "        prompt = \"Based on this device usage history:\\n\\n\"\n",
    "\n",
    "        # Group and sort events by date\n",
    "        events_by_date = {}\n",
    "        for event in sorted(history_data, key=lambda x: (x['date'], x['time'])):\n",
    "            date = event['date']\n",
    "            if date not in events_by_date:\n",
    "                events_by_date[date] = []\n",
    "            events_by_date[date].append(event)\n",
    "\n",
    "        # Format events into readable text\n",
    "        for date, events in events_by_date.items():\n",
    "            prompt += f\"Date: {date}\\n\"\n",
    "            for event in events:\n",
    "                prompt += (f\"Time: {event['time']}, Room: {event['room_id']}, \"\n",
    "                          f\"Device: {event['switchbox_id']}, State: {event['state']}\\n\")\n",
    "            prompt += \"\\n\"\n",
    "        \n",
    "        prompt += \"Device Summary:\\n\"\n",
    "        for device, info in device_patterns.items():\n",
    "            prompt += f\"Device {device} in {info['room']}\\n\"\n",
    "        prompt += \"\\n\"\n",
    "\n",
    "        prompt += \"\"\"Create a schedule following theses rules:\n",
    "        1. Each schedule must contain two actions for the same device\n",
    "        2. First action should use \"NN\" state to keep current light state\n",
    "        3. Second action should use \"NX\" state where X is the desired fan speed (0-4)\n",
    "        4. Time must match when the pattern consistently occurs(in HHMMSS format)\n",
    "        5. Generate a unique schedule ID starting with \"ID\" followed by current timestamp\n",
    "        6. Schedule ID must be in format ID<YYYYMMDD><HHMMSS>01\n",
    "            Example format (using actual device ID from above):\n",
    "{\n",
    "  \"list\": [\n",
    "    [\"ONF\", \"2LF25092023114529\", \"NN\", \"ID2024102907000001\"],\n",
    "    [\"ONF\", \"2LF25092023114529\", \"N0\", \"ID2024102907000001\"]\n",
    "  ],\n",
    "  \"id\": \"ID2024102907000001\",\n",
    "  \"time\": \"070000\"\n",
    "}\n",
    "\n",
    "        Respond only with the JSON schedule. \"\"\"\n",
    "\n",
    "        return prompt\n",
    "\n",
    "    def _format_chat_message(self, system_prompt: str, user_prompt: str) -> str:\n",
    "        \"\"\"Format prompts in LLaMA 2 chat format.\"\"\"\n",
    "        return f\"\"\"<s>[INST] <<SYS>>\n",
    "{system_prompt}\n",
    "<</SYS>>\n",
    "\n",
    "{user_prompt} [/INST]\"\"\"\n",
    "\n",
    "    def _generate_schedule_id(self) -> str:\n",
    "        \"\"\"Generate unique schedule ID.\"\"\"\n",
    "        return f\"ID{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "\n",
    "    def _validate_schedule(self, schedule: Dict) -> Dict:\n",
    "        \"\"\"Validate and fix schedule format if needed.\"\"\"\n",
    "        try:\n",
    "            valid_devices = set(event['switchbox_id'] for event in history_data)\n",
    "            \n",
    "            # Get device ID from schedule\n",
    "            device_id = schedule[\"list\"][0][1]\n",
    "            \n",
    "            # If device_id is literally 'device_id' or invalid, use the first device from history\n",
    "            if device_id == 'device_id' or device_id not in valid_devices:\n",
    "                device_id = next(iter(valid_devices))\n",
    "\n",
    "\n",
    "            # Generate proper schedule ID\n",
    "            current_date = datetime.now().strftime('%Y%m%d')\n",
    "            time = schedule.get('time', '070000')             # set 7 am default\n",
    "            sequence = '01'\n",
    "            proper_id = f\"ID{current_date}{time}{sequence}\"\n",
    "\n",
    "            # new schedule with proper formatting\n",
    "            fixed_schedule = {\n",
    "                \"list\": [\n",
    "                    [\"ONF\", schedule[\"list\"][0][1], \"NN\", proper_id],\n",
    "                    [\"ONF\", schedule[\"list\"][1][1], \"N0\", proper_id]\n",
    "                ],\n",
    "                \"id\": proper_id,\n",
    "                \"time\": time\n",
    "            }\n",
    "\n",
    "            return fixed_schedule\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error validating schedule: {str(e)}\")\n",
    "            return self._create_fallback_schedule()\n",
    "\n",
    "    def _parse_llm_response(self, response: str) -> Dict:\n",
    "        \"\"\"Parse LLaMA 2 response to extract schedule.\"\"\"\n",
    "        try:\n",
    "            # Find the last occurrence of a JSON object in the response\n",
    "            json_matches = list(re.finditer(r'\\{[^{]*\"list\":[^\\]]*\\][^}]*\\}', response, re.DOTALL))\n",
    "\n",
    "            if json_matches:\n",
    "                # Take the last match as it's likely the actual response\n",
    "                json_str = json_matches[-1].group(0)\n",
    "                try:\n",
    "                    schedule = json.loads(json_str)\n",
    "                    return self._validate_schedule(schedule)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Failed to parse extracted JSON: {json_str}\")\n",
    "\n",
    "            print(\"No valid JSON found in response\")\n",
    "            return self._create_fallback_schedule()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in parse_llm_response: {str(e)}\")\n",
    "            return self._create_fallback_schedule()\n",
    "\n",
    "\n",
    "    def _create_fallback_schedule(self) -> Dict:\n",
    "        \"\"\"Create a basic fallback schedule if parsing fails.\"\"\"\n",
    "        current_date = datetime.now().strftime('%Y%m%d')\n",
    "        time = \"070000\"  # Default to 7 AM\n",
    "        sequence = \"01\"\n",
    "        schedule_id = f\"ID{current_date}{time}{sequence}\"\n",
    "        # before ka schedule_id = self._generate_schedule_id()\n",
    "        return {\n",
    "            \"list\": [\n",
    "                [\"ONF\", \"2LF25092023114529\", \"NN\", schedule_id],\n",
    "                [\"ONF\", \"2LF25092023114529\", \"N0\", schedule_id]\n",
    "\n",
    "            ],\n",
    "            \"id\": schedule_id,\n",
    "            \"time\": time\n",
    "        }\n",
    "\n",
    "\n",
    "    def generate_schedule(self, history_data: List[Dict]) -> Dict:\n",
    "        \"\"\"Generate automation schedule based on historical data.\"\"\"\n",
    "        try:\n",
    "            # Create prompts\n",
    "            system_prompt = self._create_system_prompt()\n",
    "            user_prompt = self._create_user_prompt(history_data)\n",
    "            chat_message = self._format_chat_message(system_prompt, user_prompt)\n",
    "\n",
    "            # Generate response using LLaMA 2\n",
    "            inputs = self.tokenizer(\n",
    "                chat_message,\n",
    "                return_tensors = \"pt\",\n",
    "                padding = True,\n",
    "                truncation = True,\n",
    "                max_length = 2048\n",
    "            ).to(self.model.device)\n",
    "\n",
    "\n",
    "            outputs = self.model.generate(\n",
    "                inputs.input_ids,\n",
    "                attention_mask = inputs.attention_mask,\n",
    "                max_new_tokens = 500,\n",
    "                temperature = 0.1,\n",
    "                do_sample = True,\n",
    "                top_p = 0.95,\n",
    "                repetition_penalty = 1.2,\n",
    "                pad_token_id = self.tokenizer.eos_token_id, #for JSON formatting\n",
    "                eos_token_id = self.tokenizer.eos_token_id, #for JSON formatting\n",
    "                early_stopping=True\n",
    "            )\n",
    "\n",
    "\n",
    "            response = self.tokenizer.decode(outputs[0], skip_special_tokens = True)\n",
    "            #print(\"Raw model  response:\", response)\n",
    "\n",
    "\n",
    "            schedule = self._parse_llm_response(response)\n",
    "            return schedule\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating schedule: {str(e)}\")\n",
    "            return self._create_fallback_schedule()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample history data\n",
    "\n",
    "    history_data = [\n",
    "    {\n",
    "        \"room_id\": \"Living Room\",\n",
    "        \"switchbox_id\": \"4LLLL010820230143\",\n",
    "        \"state\": \"1000\",\n",
    "        \"date\": \"2024-10-27\",\n",
    "        \"time\": \"080000\"\n",
    "    },\n",
    "    {\n",
    "        \"room_id\": \"Living Room\",\n",
    "        \"switchbox_id\": \"2LF25092023114529\",\n",
    "        \"state\": \"03\",\n",
    "        \"date\": \"2024-10-27\",\n",
    "        \"time\": \"210000\"\n",
    "    },\n",
    "    {\n",
    "        \"room_id\": \"Main Bedroom\",\n",
    "        \"switchbox_id\": \"4LLLF20207438279\",\n",
    "        \"state\": \"10004\",\n",
    "        \"date\": \"2024-10-27\",\n",
    "        \"time\": \"213000\"\n",
    "    },\n",
    "    {\n",
    "        \"room_id\": \"Living Room\",\n",
    "        \"switchbox_id\": \"4LLLL010820230143\",\n",
    "        \"state\": \"0000\",\n",
    "        \"date\": \"2024-10-27\",\n",
    "        \"time\": \"220000\"\n",
    "    },\n",
    "    {\n",
    "        \"room_id\": \"Living Room\",\n",
    "        \"switchbox_id\": \"2LF25092023114529\",\n",
    "        \"state\": \"00\",\n",
    "        \"date\": \"2024-10-28\",\n",
    "        \"time\": \"070000\"\n",
    "    },\n",
    "    {\n",
    "        \"room_id\": \"Main Bedroom\",\n",
    "        \"switchbox_id\": \"4LLLF20207438279\",\n",
    "        \"state\": \"10003\",\n",
    "        \"date\": \"2024-10-28\",\n",
    "        \"time\": \"200000\"\n",
    "    },\n",
    "    {\n",
    "        \"room_id\": \"Guest Room\",\n",
    "        \"switchbox_id\": \"3LLF01122023123034\",\n",
    "        \"state\": \"002\",\n",
    "        \"date\": \"2024-10-28\",\n",
    "        \"time\": \"210000\"\n",
    "    },\n",
    "    {\n",
    "        \"room_id\": \"Main Bedroom\",\n",
    "        \"switchbox_id\": \"4LLLF20207438279\",\n",
    "        \"state\": \"01002\",\n",
    "        \"date\": \"2024-10-28\",\n",
    "        \"time\": \"223000\"\n",
    "    },\n",
    "    {\n",
    "        \"room_id\": \"Living Room\",\n",
    "        \"switchbox_id\": \"2LF25092023114529\",\n",
    "        \"state\": \"04\",\n",
    "        \"date\": \"2024-10-28\",\n",
    "        \"time\": \"210000\"\n",
    "    },\n",
    "    {\n",
    "        \"room_id\": \"Living Room\",\n",
    "        \"switchbox_id\": \"2LF25092023114529\",\n",
    "        \"state\": \"00\",\n",
    "        \"date\": \"2024-10-29\",\n",
    "        \"time\": \"070000\"\n",
    "    },\n",
    "    {\n",
    "        \"room_id\": \"Guest Room\",\n",
    "        \"switchbox_id\": \"3LLF01122023123034\",\n",
    "        \"state\": \"001\",\n",
    "        \"date\": \"2024-10-29\",\n",
    "        \"time\": \"073000\"\n",
    "    },\n",
    "    {\n",
    "        \"room_id\": \"Main Bedroom\",\n",
    "        \"switchbox_id\": \"4LLLF20207438279\",\n",
    "        \"state\": \"10103\",\n",
    "        \"date\": \"2024-10-29\",\n",
    "        \"time\": \"093000\"\n",
    "    },\n",
    "    {\n",
    "        \"room_id\": \"Living Room\",\n",
    "        \"switchbox_id\": \"4LLLL010820230143\",\n",
    "        \"state\": \"0100\",\n",
    "        \"date\": \"2024-10-29\",\n",
    "        \"time\": \"180000\"\n",
    "    },\n",
    "    {\n",
    "        \"room_id\": \"Living Room\",\n",
    "        \"switchbox_id\": \"2LF25092023114529\",\n",
    "        \"state\": \"02\",\n",
    "        \"date\": \"2024-10-29\",\n",
    "        \"time\": \"210000\"\n",
    "    },\n",
    "    {\n",
    "        \"room_id\": \"Main Bedroom\",\n",
    "        \"switchbox_id\": \"4LLLF20207438279\",\n",
    "        \"state\": \"00102\",\n",
    "        \"date\": \"2024-10-29\",\n",
    "        \"time\": \"223000\"\n",
    "    }\n",
    "]\n",
    "\n",
    "    # Initialize automation system\n",
    "    automation = LLaMA2HomeAutomation(model_size = \"7B\")\n",
    "\n",
    "    # Generate schedule\n",
    "    schedule = automation.generate_schedule(history_data)\n",
    "\n",
    "    # Print result\n",
    "    print(\"\\nGenerated Schedule:\")\n",
    "    print(json.dumps(schedule, indent = 2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
